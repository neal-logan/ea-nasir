{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (fc.py, line 34)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3577\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 7\u001b[1;36m\n\u001b[1;33m    import methods.fc as fc\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32mc:\\Users\\haits\\projects\\ea-nasir\\methods\\fc.py:34\u001b[1;36m\u001b[0m\n\u001b[1;33m    pred_feature : str) -> pd.DataFrame\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ibis\n",
    "import matplotlib.pyplot as plt\n",
    "import methods.prep as prep\n",
    "import methods.vis as vis\n",
    "import methods.fc as fc\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(vis)\n",
    "importlib.reload(prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = ibis.connect(\"duckdb://\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ibis.read_csv('data_forecasting/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dev/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into model development (training + validation) (2007-01-01 to 2019-12-31) \n",
    "dev_data = data.filter(data.DATE.year() >= 2007).filter(data.DATE.year() <= 2019)\n",
    "\n",
    "# and holdout test set (2020-01-01 to the end of the dataset in late 2024)\n",
    "test_data = data.filter(data.DATE.year() >= 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check for seasonality, a look at an annual decomposition of the price of copper futures.\n",
    "\n",
    "There might well be some seasonal effects in price level, but if so, they seem subtle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(prep)\n",
    "annual_decomp_features = [\n",
    "    'COPPER_OPEN_NOMINAL'\n",
    "]\n",
    "annual_decomp = prep.annual_decomposition(\n",
    "    dev_data,\n",
    "    decomp_features=annual_decomp_features\n",
    ")\n",
    "annual_decomp.to_pandas().sort_values('DATE').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(vis)\n",
    "vis.plot_decomp(\n",
    "    annual_decomp,\n",
    "    colormap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationarity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For forecasting, features should be stationary, meaning that no significant trends or seasonal patterns should be present in the data.  The mean and variance should be consistent throughout the time period.\n",
    "\n",
    "No features are stationary without differencing.  The trends are enormous, and while it's difficult to see, some degree of seasonality is almost certainly present.  Many of these look pretty good at first differencing, but we'll want to do additional tests to be confident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = [\n",
    "    'DATE',\n",
    "    'COPPER_OPEN_NOMINAL',\n",
    "    'COPPER_OPEN_REAL'\n",
    "]\n",
    "df = dev_data.select(column_list).to_pandas()\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df = df.sort_values('DATE')\n",
    "fig, axes = vis.plot_time_series_diffs(\n",
    "    df, \n",
    "    num_diffs = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Stationarity Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ADF Test  \n",
    "Functions and interpretation from [statsmodels](https://www.statsmodels.org/stable/examples/notebooks/generated/stationarity_detrending_adf_kpss.html)\n",
    "\n",
    "This statistical test checks for a unit root.  If we fail to reject the null hypothesis, the series may be nonstationary.  In this case, the p-value is about 0.19 without differencing and 0.00000 differenced once, suggesting that differencing once is probably appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def adf_test(timeseries):\n",
    "    print(\"Results of Dickey-Fuller Test:\")\n",
    "    dftest = adfuller(timeseries, autolag=\"AIC\")\n",
    "    dfoutput = pd.Series(\n",
    "        dftest[0:4],\n",
    "        index=[\n",
    "            \"Test Statistic\",\n",
    "            \"p-value\",\n",
    "            \"#Lags Used\",\n",
    "            \"Number of Observations Used\",\n",
    "        ],\n",
    "    )\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput[\"Critical Value (%s)\" % key] = value\n",
    "    print(dfoutput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import kpss\n",
    "\n",
    "df = dev_data.to_pandas().sort_values('DATE')[['DATE','COPPER_OPEN_NOMINAL']]\n",
    "adf_test(df['COPPER_OPEN_NOMINAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_test(df['COPPER_OPEN_NOMINAL'].diff().dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KPSS Test\n",
    "Functions and interpretation from [statsmodels](https://www.statsmodels.org/stable/examples/notebooks/generated/stationarity_detrending_adf_kpss.html)\n",
    "\n",
    "In this test, the null and alternate hypothesis are reversed: if we reject the null hypothesis, we have evidence that the series is not stationary.  The p-values here are 'higher than 0.01' without differencing and 'higher than 0.1' differenced once, so we can be reasonably confident in rejecting the null hypothesis differencing once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import kpss\n",
    "\n",
    "def kpss_test(timeseries):\n",
    "    print(\"Results of KPSS Test:\")\n",
    "    kpsstest = kpss(timeseries, regression=\"c\", nlags=\"auto\")\n",
    "    kpss_output = pd.Series(\n",
    "        kpsstest[0:3], index=[\"Test Statistic\", \"p-value\", \"Lags Used\"]\n",
    "    )\n",
    "    for key, value in kpsstest[3].items():\n",
    "        kpss_output[\"Critical Value (%s)\" % key] = value\n",
    "\n",
    "    print(kpss_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dev_data.to_pandas().sort_values('DATE')[['DATE','COPPER_OPEN_NOMINAL']]\n",
    "kpss_test(df['COPPER_OPEN_NOMINAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpss_test(df['COPPER_OPEN_NOMINAL'].diff().dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt at Long-Term Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key tools:\n",
    "- [skforecast](https://skforecast.org/)\n",
    "- [pmdarima](https://github.com/alkaline-ml/pmdarima)\n",
    "- [sklearn scaling]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.sarimax import Sarimax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Validate Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training data (2007-2018) \n",
    "train_data = dev_data.filter(dev_data.DATE.year() >= 2007).filter(dev_data.DATE.year() <= 2018)\n",
    "\n",
    "# and validation set (2019 only)\n",
    "val_data = dev_data.filter(dev_data.DATE.year() == 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_data.to_pandas()\n",
    "train_df['DATE'] = pd.to_datetime(train_df['DATE'])\n",
    "train_df = train_df.sort_values('DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = val_data.to_pandas()\n",
    "val_df['DATE'] = pd.to_datetime(val_df['DATE'])\n",
    "val_df = val_df.sort_values('DATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pure ARIMA models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDQ = 1,1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pdq = (1,1,1) # p autoregression lags, d differences, q moving average\n",
    "model = Sarimax(order = pdq)\n",
    "model.fit(\n",
    "    y = train_df['COPPER_OPEN_NOMINAL'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(steps = len(val_df))\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(12, 6))\n",
    "\n",
    "plt.plot(train_df['DATE'],\n",
    "    train_df['COPPER_OPEN_NOMINAL'],\n",
    "    label = 'Training')\n",
    "\n",
    "plt.plot(val_df['DATE'],\n",
    "    val_df['COPPER_OPEN_NOMINAL'],\n",
    "    label = 'Validation')\n",
    "\n",
    "plt.plot(val_df['DATE'],\n",
    "         pred,\n",
    "         label = 'Prediction')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDQ = 1,2,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdq = (1,2,1) # p autoregression lags, d differences, q moving average\n",
    "model = Sarimax(order = pdq)\n",
    "model.fit(y = train_df['COPPER_OPEN_NOMINAL'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(steps = len(val_df))\n",
    "fig, ax=plt.subplots(figsize=(12, 6))\n",
    "\n",
    "plt.plot(train_df['DATE'],\n",
    "    train_df['COPPER_OPEN_NOMINAL'],\n",
    "    label = 'Training')\n",
    "\n",
    "plt.plot(val_df['DATE'],\n",
    "    val_df['COPPER_OPEN_NOMINAL'],\n",
    "    label = 'Validation')\n",
    "\n",
    "plt.plot(val_df['DATE'],\n",
    "         pred,\n",
    "         label = 'Prediction')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple ARIMAX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dev_data.to_pandas()\n",
    "exog_cols = [col for col in df.columns if '_OPEN' in col]\n",
    "exog = df[exog_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdq = (1,1,1) # p autoregression lags, d differences, q moving average\n",
    "model = Sarimax(order = pdq)\n",
    "model.fit(\n",
    "    y = df['COPPER_PRICE'],\n",
    "    exog = exog)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dev_data.to_pandas()\n",
    "(df['COPPER_OPEN'] - df['COPPER_OPEN'].mean())/df['COPPER_OPEN'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dev_data.to_pandas()\n",
    "exog_cols = [col for col in df.columns if '_OPEN' in col]\n",
    "exog = df[exog_cols]\n",
    "exog = exog.drop(['NATGAS_OPEN','GOLD_OPEN','CORN_OPEN'], axis='columns')\n",
    "exog = (exog - exog.mean())/exog.std()\n",
    "\n",
    "target = df['COPPER_PRICE']\n",
    "target = (target - target.mean())/target.std()\n",
    "\n",
    "pdq = (1,1,1) # p autoregression lags, d differences, q moving average\n",
    "model = Sarimax(order = pdq)\n",
    "model.fit(\n",
    "    y = target,\n",
    "    exog = exog)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily Sliding Window Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These predictions look just one day ahead, using models trained on a shorter window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = dev_data.to_pandas()\n",
    "dev_df['DATE'] = pd.to_datetime(dev_df['DATE'])\n",
    "dev_df = dev_df.sort_values('DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(fc)\n",
    "dev_df = fc.sliding_window_arima_predictions(\n",
    "    data = dev_df,\n",
    "    target_name= 'COPPER_OPEN_NOMINAL',\n",
    "    pdq = (1,2,1),\n",
    "    window_size=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(fc)\n",
    "dev_df = fc.add_fc_eval_columns(\n",
    "    df = dev_df,\n",
    "    pred_feature = 'COPPER_OPEN_NOMINAL'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'DATE',\n",
    "    \n",
    "    'COPPER_OPEN_NOMINAL_DELTA_SIGN',\n",
    "    'COPPER_OPEN_NOMINAL_DELTA_SIGN_PRED',\n",
    "    'COPPER_OPEN_NOMINAL_DELTA_SIGN_PRODUCT',\n",
    "\n",
    "    'COPPER_OPEN_NOMINAL_DELTA_ERRVAL',\n",
    "    'COPPER_OPEN_NOMINAL_DELTA_ERRABS',\n",
    "    \n",
    "    'COPPER_OPEN_NOMINAL_DELTA',\n",
    "    'COPPER_OPEN_NOMINAL_DELTA_PRED',\n",
    "    \n",
    "    'COPPER_OPEN_NOMINAL',\n",
    "    'COPPER_OPEN_NOMINAL_PRED',\n",
    "]\n",
    "dev_df[columns].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean absolute error:  \" + str(dev_df['COPPER_OPEN_NOMINAL_ERRABS'].dropna().sum() / dev_df['COPPER_OPEN_NOMINAL_ERRABS'].dropna().count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is right on the direction of price changes just slightly more often than it's wrong "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean product of signs:  \" + str(dev_df['COPPER_OPEN_NOMINAL_DELTA_SIGN_PRODUCT'].dropna().sum() / dev_df['COPPER_OPEN_NOMINAL_DELTA_SIGN_PRODUCT'].dropna().count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when the model is wrong on direction, the prices changes tend to be slightly larger, bringing the expected value of simple directional trading on this model very close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_trade_value = np.sum(dev_df['COPPER_OPEN_NOMINAL_DELTA_SIGN_PRODUCT'].dropna() * np.abs(dev_df['COPPER_OPEN_NOMINAL_DELTA'].dropna()))\n",
    "mean_expected_trade_value = expected_trade_value / dev_df['COPPER_OPEN_NOMINAL_DELTA_SIGN_PRODUCT'].dropna().count()\n",
    "\n",
    "print(\"Mean expected daily trade yields for single-contract directional trading:  \" + str(mean_expected_trade_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export Data for Agent Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data.to_pandas().to_csv('data_forecasting/dev_data.csv')\n",
    "test_data.to_pandas().to_csv('data_forecasting/test_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
